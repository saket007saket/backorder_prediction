{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\SAKET NANDAN\\Documents\\current_hackathon\\backorder_prediction\\Back order prediction\\data_no_null_in_target.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df[['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month', 'sales_1_month', 'sales_9_month','went_on_backorder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_9_month</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687855</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687856</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687857</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687858</th>\n",
       "      <td>62.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687859</th>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1687860 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0                 0.0        NaN             0.0               0.0   \n",
       "1                 2.0        9.0             0.0               0.0   \n",
       "2                 2.0        NaN             0.0               0.0   \n",
       "3                 7.0        8.0             0.0               0.0   \n",
       "4                 8.0        NaN             0.0               0.0   \n",
       "...               ...        ...             ...               ...   \n",
       "1687855           0.0        2.0             0.0              10.0   \n",
       "1687856          -1.0        NaN             0.0               5.0   \n",
       "1687857          -1.0        9.0             0.0               7.0   \n",
       "1687858          62.0        9.0            16.0              39.0   \n",
       "1687859          19.0        4.0             0.0               0.0   \n",
       "\n",
       "         sales_1_month  sales_9_month  went_on_backorder  \n",
       "0                  0.0            0.0                  0  \n",
       "1                  0.0            0.0                  0  \n",
       "2                  0.0            0.0                  0  \n",
       "3                  0.0            0.0                  0  \n",
       "4                  0.0            4.0                  0  \n",
       "...                ...            ...                ...  \n",
       "1687855            0.0            7.0                  0  \n",
       "1687856            1.0            8.0                  0  \n",
       "1687857            0.0           12.0                  1  \n",
       "1687858           35.0          205.0                  0  \n",
       "1687859            2.0           20.0                  0  \n",
       "\n",
       "[1687860 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1687860 entries, 0 to 1687859\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   national_inv       1687860 non-null  float64\n",
      " 1   lead_time          1586967 non-null  float64\n",
      " 2   in_transit_qty     1687860 non-null  float64\n",
      " 3   forecast_3_month   1687860 non-null  float64\n",
      " 4   sales_1_month      1687860 non-null  float64\n",
      " 5   sales_9_month      1687860 non-null  float64\n",
      " 6   went_on_backorder  1687860 non-null  int64  \n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 90.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1181502, 6), (506358, 6))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's divide into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels='went_on_backorder', axis=1),  # predictors\n",
    "    data['went_on_backorder'],  # target\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from feature-engine\n",
    "from feature_engine import missing_data_imputers as mdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanMedianImputer(imputation_method='median', variables=['lead_time'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_imputer= mdi.MeanMedianImputer(imputation_method='median', variables = ['lead_time'])\n",
    "median_imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's transform the data with the pipeline\n",
    "X_train_imp= median_imputer.transform(X_train)\n",
    "X_test_imp= median_imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking after imputation about whether null values removed from both train and test data set or not \n",
    "#X_train_imp.isnull().sum()\n",
    "#X_test_imp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing Undersampling for Handling Imbalanced \n",
    "nm = NearMiss()#NearMiss do not take random_state arguement \n",
    "X_train_under_samp,y_train_under_samp = nm.fit_sample(X_train_imp,y_train)\n",
    "X_test_under_samp,y_test_under_samp = nm.fit_sample(X_test_imp,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [note:- while trying for bulk test ,we should also use the test data_set on which undersampling is already performed becuse i have trained our model 1:1 ratio of target binary label ,if will use to test the highly imbalnced data set then it will give high overfitting problem ] \n",
    "\n",
    "#### if u argue that why i went for this under sampling ?\n",
    "#### ans:- becoz i used this under sampling to created user interface in which i m taking only one test case , in that case there is no chance of imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_under_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis , QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import lightgbm as lgb#  for this i have to install package  \"  !pip install lightgbm \"\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV , KFold , cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification metrices\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report, precision_score,recall_score,f1_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Logistic Regression\", \"Nearest Neighbors\", \"Naive Bayes\", \"Linear SVM\", \"RBF SVM\", \n",
    "          \"Decision Tree\", \"Random Forest\", \"AdaBoost\", \"Gradient Boosting\", \n",
    "         \"LDA\", \"QDA\", \"Neural Net\", \"LightGBM\", \"XGBoost\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(5),\n",
    "    GaussianNB(),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(kernel = \"rbf\", gamma=2, C=1),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    lgb.LGBMClassifier(),    \n",
    "    xgb.XGBClassifier()\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  :  0.9193\n",
      "Nearest Neighbors  :  0.9249\n",
      "Naive Bayes  :  0.8791\n",
      "Linear SVM  :  0.9173\n",
      "RBF SVM  :  0.928\n",
      "Decision Tree  :  0.9257\n",
      "Random Forest  :  0.9295\n",
      "AdaBoost  :  0.9267\n",
      "Gradient Boosting  :  0.9321\n",
      "LDA  :  0.4821\n",
      "QDA  :  0.4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAKET NANDAN\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net  :  0.9299\n",
      "LightGBM  :  0.9308\n",
      "XGBoost  :  0.9302\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "roc_auc_score=[]\n",
    "# iterate over classifiers and predict accuracy\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train_under_samp, y_train_under_samp)\n",
    "    score = clf.score(X_test_under_samp, y_test_under_samp)\n",
    "    score = round(score, 4)\n",
    "    accuracy_scores.append(score)\n",
    "    print(name ,' : ' , score )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifiers</th>\n",
       "      <th>Accuracy Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nearest Neighbors</td>\n",
       "      <td>0.9249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.8791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.9173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>0.9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.9267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.9321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.4821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>0.9299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.9308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.9302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifiers  Accuracy Scores\n",
       "0   Logistic Regression           0.9193\n",
       "1     Nearest Neighbors           0.9249\n",
       "2           Naive Bayes           0.8791\n",
       "3            Linear SVM           0.9173\n",
       "4               RBF SVM           0.9280\n",
       "5         Decision Tree           0.9257\n",
       "6         Random Forest           0.9295\n",
       "7              AdaBoost           0.9267\n",
       "8     Gradient Boosting           0.9321\n",
       "9                   LDA           0.4821\n",
       "10                  QDA           0.4999\n",
       "11           Neural Net           0.9299\n",
       "12             LightGBM           0.9308\n",
       "13              XGBoost           0.9302"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers_performance = pd.DataFrame({\"Classifiers\": names, \"Accuracy Scores\": accuracy_scores})\n",
    "classifiers_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifiers</th>\n",
       "      <th>Accuracy Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.9321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.9308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.9302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>0.9299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>0.9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.9267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.9257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nearest Neighbors</td>\n",
       "      <td>0.9249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.9173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.8791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.4821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifiers  Accuracy Scores\n",
       "8     Gradient Boosting           0.9321\n",
       "12             LightGBM           0.9308\n",
       "13              XGBoost           0.9302\n",
       "11           Neural Net           0.9299\n",
       "6         Random Forest           0.9295\n",
       "4               RBF SVM           0.9280\n",
       "7              AdaBoost           0.9267\n",
       "5         Decision Tree           0.9257\n",
       "1     Nearest Neighbors           0.9249\n",
       "0   Logistic Regression           0.9193\n",
       "3            Linear SVM           0.9173\n",
       "2           Naive Bayes           0.8791\n",
       "10                  QDA           0.4999\n",
       "9                   LDA           0.4821"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing accuracy score in descending order\n",
    "classifiers_performance.sort_values(by = 'Accuracy Scores' , ascending = False)[['Classifiers', 'Accuracy Scores']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will perform grid search to hyperparameter tunnig  to find best parameter for each of the top 3 classification algo in above chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                  criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=100,\n",
       "                                                  n_iter_no_c...\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.1, 0.05, 0.01],\n",
       "                         'loss': ['deviance'], 'max_depth': [3, 4, 8],\n",
       "                         'min_samples_leaf': [50, 75, 100, 150],\n",
       "                         'n_estimators': [40, 50, 100, 200, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "gbc_params = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [40,50,100,200,300],\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth': [3,4, 8],\n",
    "              'min_samples_leaf': [50,75,100,150], \n",
    "              }\n",
    "\n",
    "gbc_grid_search = GridSearchCV(estimator = gbc_clf, \n",
    "                               param_grid = gbc_params, \n",
    "                               scoring = \"accuracy\", \n",
    "                               cv = 5,\n",
    "                               verbose = 0)\n",
    "\n",
    "gbc_grid_search.fit(X_train_under_samp,y_train_under_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting GridSearch CV best score : 0.9258\n",
      "\n",
      "\n",
      "Gradient Boosting GridSearch CV roc_auc score : 0.9258\n",
      "\n",
      "\n",
      "Gradient Boosting Parameters that give the best results : \n",
      "\n",
      " {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 8, 'min_samples_leaf': 100, 'n_estimators': 100}\n",
      "\n",
      "\n",
      "Gradient Boosting Estimator that was chosen by the search : \n",
      "\n",
      " GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=8,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=100, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=42, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "\n",
    "# best score achieved during the GridSearchCV\n",
    "print('Gradient Boosting GridSearch CV best score : {:.4f}\\n\\n'.format(gbc_grid_search.best_score_))\n",
    "\n",
    "print('Gradient Boosting GridSearch CV roc_auc score : {:.4f}\\n\\n'.format(gbc_grid_search.best_score_))\n",
    "\n",
    "\n",
    "# print parameters that give the best results\n",
    "print('Gradient Boosting Parameters that give the best results :','\\n\\n', (gbc_grid_search.best_params_))\n",
    "\n",
    "# print estimator that was chosen by the GridSearch\n",
    "gbc_best = gbc_grid_search.best_estimator_\n",
    "print('\\n\\nGradient Boosting Estimator that was chosen by the search :','\\n\\n', (gbc_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set\n",
      "Gradient boosting Classifier model accuracy score for train set : 0.9304\n",
      "test set\n",
      "Gradient boosting Classifier model accuracy score for test set : 0.9298\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      " [[3260  143]\n",
      " [ 335 3068]]\n",
      "\n",
      "True Positives(TP) =  3260\n",
      "\n",
      "True Negatives(TN) =  3068\n",
      "\n",
      "False Positives(FP){type 1 error} =  143\n",
      "\n",
      "False Negatives(FN){type 2 error} =  335\n",
      "\n",
      "\n",
      "\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      3403\n",
      "           1       0.96      0.90      0.93      3403\n",
      "\n",
      "    accuracy                           0.93      6806\n",
      "   macro avg       0.93      0.93      0.93      6806\n",
      "weighted avg       0.93      0.93      0.93      6806\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification accuracy : 0.9298\n",
      "\n",
      "\n",
      "\n",
      "Classification error : 0.0702\n",
      "\n",
      "\n",
      "\n",
      "Precision : 0.9580\n",
      "\n",
      "\n",
      "\n",
      "Recall or Sensitivity : 0.9068\n",
      "\n",
      "\n",
      "\n",
      "True Positive Rate : 0.9068\n",
      "\n",
      "\n",
      "\n",
      "False Positive Rate : 0.0445\n",
      "\n",
      "\n",
      "\n",
      "Specificity : 0.9555\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " gbc_clf = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.1, loss='deviance', max_depth=8,\n",
    "                           max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=100, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_iter_no_change=None, presort='deprecated',\n",
    "                           random_state=42, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=False)\n",
    "    \n",
    "gbc_clf.fit(X_train_under_samp, y_train_under_samp)\n",
    "#predict train set \n",
    "print('train set')\n",
    "y1_pred = gbc_clf.predict(X_train_under_samp)\n",
    "# print the accuracy\n",
    "print('Gradient boosting Classifier model accuracy score for train set : {0:0.4f}'. format(accuracy_score(y_train_under_samp, y1_pred)))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#predict test set\n",
    "print('test set')\n",
    "y2_pred = gbc_clf.predict(X_test_under_samp)\n",
    "# print the accuracy\n",
    "print('Gradient boosting Classifier model accuracy score for test set : {0:0.4f}\\n\\n'. format(accuracy_score(y_test_under_samp, y2_pred)))\n",
    "\n",
    "#-------------------------------------------------confusion matrix-----------------------------------------------------------\n",
    "\n",
    "# print confusion-matrix\n",
    "\n",
    "cm = confusion_matrix(y_test_under_samp, y2_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP){type 1 error} = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN){type 2 error} = ', cm[1,0])\n",
    "print('\\n\\n')\n",
    "\n",
    "#-------------------------------visualization of confusion matrix -----------------------------------------------------------\n",
    "\n",
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "\n",
    "#----------------------------------classification report ----------------------------------------------------------------------\n",
    "print('classification report')\n",
    "print(classification_report(y_test_under_samp, y2_pred))\n",
    "print('\\n\\n')\n",
    "#-----------------------------------classification accuracy -------------------------------------------------------------------\n",
    "TP = cm[0,0]\n",
    "TN = cm[1,1]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "\n",
    "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))\n",
    "print('\\n\\n')\n",
    "\n",
    "#----------------------------------------classification error------------------------------------------------------------------\n",
    "\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification error : {0:0.4f}'.format(classification_error))\n",
    "print('\\n\\n')\n",
    "\n",
    "#----------------------------------------precision-----------------------------------------------------------------------------\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print('Precision : {0:0.4f}'.format(precision))\n",
    "print('\\n\\n')\n",
    "\n",
    "#--------------------------------------------Recall---------------------------------------------------------------------------\n",
    "recall = TP / float(TP + FN)\n",
    "\n",
    "print('Recall or Sensitivity : {0:0.4f}'.format(recall))\n",
    "print('\\n\\n')\n",
    "#--------------------------------------Truepositive rate------------------------------------------------------------------------\n",
    "\n",
    "true_positive_rate = TP / float(TP + FN)\n",
    "\n",
    "print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))\n",
    "print('\\n\\n')\n",
    "\n",
    "#--------------------------------------false positive rate---------------------------------------------------------------------\n",
    "false_positive_rate = FP / float(FP + TN)\n",
    "\n",
    "print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))\n",
    "print('\\n\\n')\n",
    "#------------------------------------------ Specificity (True Negative Rate) --------------------------------------------------\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print('Specificity : {0:0.4f}'.format(specificity))\n",
    "print('\\n\\n')\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                      colsample_bytree=1.0,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.1, max_depth=-1,\n",
       "                                      min_child_samples=20,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=100,\n",
       "                                      n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                      random_state=None, reg_alpha=0.0,\n",
       "                                      reg_lambda=0.0, silent=Tru...\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'colsample_bytree': [0.6, 0.06, 0.006],\n",
       "                         'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         'num_leaves': [14, 15, 16, 18],\n",
       "                         'objective': ['binary'], 'random_state': [50],\n",
       "                         'reg_alpha': [1.0, 0.35, 0.045],\n",
       "                         'reg_lambda': [1.0, 0.139, 0.01],\n",
       "                         'subsample': [0.6, 0.06, 0.006]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf = lgb.LGBMClassifier()\n",
    "\n",
    "\n",
    "lgb_params={'learning_rate': [0.1,0.2,0.3,0.4,0.5], #i tried [0.1,0.5,0.8,1.0]--->[0.1,0.2,0.3,0.4,0.5]-->final [0.1]\n",
    "    'num_leaves': [14,15,16,18],           #i tried [16,20,25,50]---->[14,15,16,18]--->final[16]\n",
    "    'objective' : ['binary'],\n",
    "    'colsample_bytree' :[0.6,0.06,0.006],# i tried this range since colsample should be under range of 0 to 1 [i/10.0 for i in range(6,10)]--\n",
    "    #----->[i/10.0 for i in np.arange(6,10,0.5)]---->[0.6,0.06,0.006]--->final(0.6)\n",
    "    'subsample' :[0.6,0.06,0.006],#i tried this range [i/10.0 for i in np.arange(6,10,0.5)](0.6)---->[i/100.0 for i in np.arange(6,10,0.5)](0.06)---\n",
    "    #--->[i/1000.0 for i in np.arange(6,10,0.5)](0.006)---->[0.6,0.06,0.006]--->final(0.6)     \n",
    "    'reg_alpha':[1.0,0.35,0.045] ,#[i for i in range(1,10,2)]-->(1.0)--->[i/10.0 for i in np.arange(1,2,0.2)]----\n",
    "    #---->[i/10.0 for i in np.arange(1,10,0.5)](0.35)--->[i/100.0 for i in np.arange(1,10,0.5)](0.045)--->[1.0,0.35,0.045]-->final(0.045)\n",
    "    'reg_lambda' :[1.0,0.139,0.01],#[i for i in range(1,10,2)](1)--->[i/10.0 for i in np.arange(1,2,0.2)](0.139)\n",
    "    #--->[i/100.0 for i in np.arange(1,10,0.5)](0.01)---->[1.0,0.139,0.01]---->final[1.0]\n",
    "    'random_state':[50],#[40,45,50,75,100,1000]----final[50]\n",
    "    }\n",
    "\n",
    "\n",
    "lgb_grid_search = GridSearchCV(estimator = lgb_clf,  \n",
    "                               param_grid = lgb_params,\n",
    "                               scoring = 'accuracy',\n",
    "                               cv = 5,\n",
    "                               verbose=0)\n",
    "\n",
    "\n",
    "lgb_grid_search.fit(X_train_under_samp, y_train_under_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM GridSearch CV best score : 0.9271\n",
      "\n",
      "\n",
      "LightGBM Parameters that give the best results : \n",
      "\n",
      " {'colsample_bytree': 0.6, 'learning_rate': 0.1, 'num_leaves': 16, 'objective': 'binary', 'random_state': 50, 'reg_alpha': 0.045, 'reg_lambda': 1.0, 'subsample': 0.6}\n",
      "\n",
      "\n",
      "LightGBM Estimator that was chosen by the search : \n",
      "\n",
      " LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "               n_estimators=100, n_jobs=-1, num_leaves=16, objective='binary',\n",
      "               random_state=50, reg_alpha=0.045, reg_lambda=1.0, silent=True,\n",
      "               subsample=0.6, subsample_for_bin=200000, subsample_freq=0)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "\n",
    "# best score achieved during the GridSearchCV\n",
    "print('LightGBM GridSearch CV best score : {:.4f}\\n\\n'.format(lgb_grid_search.best_score_))\n",
    "\n",
    "# print parameters that give the best results\n",
    "print('LightGBM Parameters that give the best results :','\\n\\n', (lgb_grid_search.best_params_))\n",
    "\n",
    "# print estimator that was chosen by the GridSearch\n",
    "lgb_best = lgb_grid_search.best_estimator_\n",
    "print('\\n\\nLightGBM Estimator that was chosen by the search :','\\n\\n', (lgb_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set\n",
      "Gradient boosting Classifier model accuracy score for train set : 0.9290\n",
      "test set\n",
      "Gradient boosting Classifier model accuracy score for test set : 0.9339\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      " [[3301  102]\n",
      " [ 348 3055]]\n",
      "\n",
      "True Positives(TP) =  3301\n",
      "\n",
      "True Negatives(TN) =  3055\n",
      "\n",
      "False Positives(FP){type 1 error} =  102\n",
      "\n",
      "False Negatives(FN){type 2 error} =  348\n",
      "\n",
      "\n",
      "\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94      3403\n",
      "           1       0.97      0.90      0.93      3403\n",
      "\n",
      "    accuracy                           0.93      6806\n",
      "   macro avg       0.94      0.93      0.93      6806\n",
      "weighted avg       0.94      0.93      0.93      6806\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification accuracy : 0.9339\n",
      "\n",
      "\n",
      "\n",
      "Classification error : 0.0661\n",
      "\n",
      "\n",
      "\n",
      "Precision : 0.9700\n",
      "\n",
      "\n",
      "\n",
      "Recall or Sensitivity : 0.9046\n",
      "\n",
      "\n",
      "\n",
      "True Positive Rate : 0.9046\n",
      "\n",
      "\n",
      "\n",
      "False Positive Rate : 0.0323\n",
      "\n",
      "\n",
      "\n",
      "Specificity : 0.9677\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " lgb_clf =lgb.LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.6,\n",
    "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
    "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
    "               n_estimators=100, n_jobs=-1, num_leaves=16, objective='binary',\n",
    "               random_state=50, reg_alpha=0.045, reg_lambda=1.0, silent=True,\n",
    "               subsample=0.6, subsample_for_bin=200000, subsample_freq=0)\n",
    "    \n",
    "lgb_clf.fit(X_train_under_samp, y_train_under_samp)\n",
    "#predict train set \n",
    "print('train set')\n",
    "y1_pred = lgb_clf.predict(X_train_under_samp)\n",
    "# print the accuracy\n",
    "print('Gradient boosting Classifier model accuracy score for train set : {0:0.4f}'. format(accuracy_score(y_train_under_samp, y1_pred)))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#predict test set\n",
    "print('test set')\n",
    "y2_pred = lgb_clf.predict(X_test_under_samp)\n",
    "# print the accuracy\n",
    "print('Gradient boosting Classifier model accuracy score for test set : {0:0.4f}\\n\\n'. format(accuracy_score(y_test_under_samp, y2_pred)))\n",
    "\n",
    "#-------------------------------------------------confusion matrix-----------------------------------------------------------\n",
    "\n",
    "# print confusion-matrix\n",
    "\n",
    "cm = confusion_matrix(y_test_under_samp, y2_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP){type 1 error} = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN){type 2 error} = ', cm[1,0])\n",
    "print('\\n\\n')\n",
    "\n",
    "#-------------------------------visualization of confusion matrix -----------------------------------------------------------\n",
    "\n",
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "\n",
    "#----------------------------------classification report ----------------------------------------------------------------------\n",
    "print('classification report')\n",
    "print(classification_report(y_test_under_samp, y2_pred))\n",
    "print('\\n\\n')\n",
    "#-----------------------------------classification accuracy -------------------------------------------------------------------\n",
    "TP = cm[0,0]\n",
    "TN = cm[1,1]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "\n",
    "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))\n",
    "print('\\n\\n')\n",
    "\n",
    "#----------------------------------------classification error------------------------------------------------------------------\n",
    "\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification error : {0:0.4f}'.format(classification_error))\n",
    "print('\\n\\n')\n",
    "\n",
    "#----------------------------------------precision-----------------------------------------------------------------------------\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print('Precision : {0:0.4f}'.format(precision))\n",
    "print('\\n\\n')\n",
    "\n",
    "#--------------------------------------------Recall---------------------------------------------------------------------------\n",
    "recall = TP / float(TP + FN)\n",
    "\n",
    "print('Recall or Sensitivity : {0:0.4f}'.format(recall))\n",
    "print('\\n\\n')\n",
    "#--------------------------------------Truepositive rate------------------------------------------------------------------------\n",
    "\n",
    "true_positive_rate = TP / float(TP + FN)\n",
    "\n",
    "print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))\n",
    "print('\\n\\n')\n",
    "\n",
    "#--------------------------------------false positive rate---------------------------------------------------------------------\n",
    "false_positive_rate = FP / float(FP + TN)\n",
    "\n",
    "print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))\n",
    "print('\\n\\n')\n",
    "#------------------------------------------ Specificity (True Negative Rate) --------------------------------------------------\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print('Specificity : {0:0.4f}'.format(specificity))\n",
    "print('\\n\\n')\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estim...\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'colsample_bytree': [0.7], 'gamma': [0.0],\n",
       "                         'learning_rate': [0.1], 'max_depth': [10, 12],\n",
       "                         'min_child_weight': [2, 3, 4], 'random_state': [50],\n",
       "                         'reg_alpha': [1, 1.2], 'reg_lambda': [1.4, 1.6],\n",
       "                         'scale_pos_weight': [1.0, 0.5], 'subsample': [0.9]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf=xgb.XGBClassifier()\n",
    "\n",
    "xgb_params={'learning_rate':[0.1],\n",
    "    'max_depth':[10,12],\n",
    "    'min_child_weight':[2,3,4],\n",
    "    'gamma':[0.0],  #note i have tuned gamma using this  'gamma':[i/10.0 for i in range(0,5)]\n",
    "    'subsample':[0.9], # i have tuned subsample using this  'subsample':[i/10.0 for i in range(6,10)]\n",
    "    'colsample_bytree':[0.7] ,#i have tuned colsample_bytree using this technique  'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "    'scale_pos_weight':[1.0,0.5],\n",
    "     'reg_alpha':[ 1,1.2],  #i have tuned using this  'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "    'reg_lambda' : [1.4,1.6],\n",
    "    'random_state':[50]\n",
    "    }\n",
    "xgb_grid_search = GridSearchCV(estimator = xgb_clf,  \n",
    "                               param_grid = xgb_params,\n",
    "                               scoring = 'accuracy',\n",
    "                               cv = 5,\n",
    "                               verbose=0)\n",
    "xgb_grid_search.fit(X_train_under_samp, y_train_under_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoosting GridSearch CV best score : 0.9265\n",
      "\n",
      "\n",
      "XGBoosting Parameters that give the best results : \n",
      "\n",
      " {'colsample_bytree': 0.7, 'gamma': 0.0, 'learning_rate': 0.1, 'max_depth': 10, 'min_child_weight': 3, 'random_state': 50, 'reg_alpha': 1.2, 'reg_lambda': 1.6, 'scale_pos_weight': 1.0, 'subsample': 0.9}\n",
      "\n",
      "\\ XGBoosting Estimator that was chosen by the search : \n",
      "\n",
      " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.7, gamma=0.0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "              min_child_weight=3, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='binary:logistic', random_state=50, reg_alpha=1.2,\n",
      "              reg_lambda=1.6, scale_pos_weight=1.0, subsample=0.9,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# examine the best model\n",
    "\n",
    "# best score achieved during the GridSearchCV\n",
    "print('XGBoosting GridSearch CV best score : {:.4f}\\n\\n'.format(xgb_grid_search.best_score_))\n",
    "\n",
    "# print parameters that give the best results\n",
    "print('XGBoosting Parameters that give the best results :','\\n\\n', (xgb_grid_search.best_params_))\n",
    "\n",
    "# print estimator that was chosen by the GridSearch\n",
    "xgb_best = xgb_grid_search.best_estimator_\n",
    "print('\\n\\ XGBoosting Estimator that was chosen by the search :','\\n\\n', (xgb_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set\n",
      "Gradient boosting Classifier model accuracy score for train set : 0.9304\n",
      "test set\n",
      "Gradient boosting Classifier model accuracy score for test set : 0.9305\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "\n",
      " [[3263  140]\n",
      " [ 333 3070]]\n",
      "\n",
      "True Positives(TP) =  3263\n",
      "\n",
      "True Negatives(TN) =  3070\n",
      "\n",
      "False Positives(FP){type 1 error} =  140\n",
      "\n",
      "False Negatives(FN){type 2 error} =  333\n",
      "\n",
      "\n",
      "\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      3403\n",
      "           1       0.96      0.90      0.93      3403\n",
      "\n",
      "    accuracy                           0.93      6806\n",
      "   macro avg       0.93      0.93      0.93      6806\n",
      "weighted avg       0.93      0.93      0.93      6806\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Classification accuracy : 0.9305\n",
      "\n",
      "\n",
      "\n",
      "Classification error : 0.0695\n",
      "\n",
      "\n",
      "\n",
      "Precision : 0.9589\n",
      "\n",
      "\n",
      "\n",
      "Recall or Sensitivity : 0.9074\n",
      "\n",
      "\n",
      "\n",
      "True Positive Rate : 0.9074\n",
      "\n",
      "\n",
      "\n",
      "False Positive Rate : 0.0436\n",
      "\n",
      "\n",
      "\n",
      "Specificity : 0.9564\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " xgb_clf =xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.7, gamma=0.0, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
    "              min_child_weight=3, monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
    "              objective='binary:logistic', random_state=50, reg_alpha=1.2,\n",
    "              reg_lambda=1.6, scale_pos_weight=1.0, subsample=0.9,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "\n",
    "    \n",
    "xgb_clf.fit(X_train_under_samp, y_train_under_samp)\n",
    "#predict train set \n",
    "print('train set')\n",
    "y1_pred = xgb_clf.predict(X_train_under_samp)\n",
    "# print the accuracy\n",
    "print(' xtra Gradient boosting Classifier model accuracy score for train set : {0:0.4f}'. format(accuracy_score(y_train_under_samp, y1_pred)))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#predict test set\n",
    "print('test set')\n",
    "y2_pred = xgb_clf.predict(X_test_under_samp)\n",
    "# print the accuracy\n",
    "print('xtra Gradient boosting Classifier model accuracy score for test set : {0:0.4f}\\n\\n'. format(accuracy_score(y_test_under_samp, y2_pred)))\n",
    "\n",
    "#-------------------------------------------------confusion matrix-----------------------------------------------------------\n",
    "\n",
    "# print confusion-matrix\n",
    "\n",
    "cm = confusion_matrix(y_test_under_samp, y2_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP){type 1 error} = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN){type 2 error} = ', cm[1,0])\n",
    "print('\\n\\n')\n",
    "\n",
    "#-------------------------------visualization of confusion matrix -----------------------------------------------------------\n",
    "\n",
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "\n",
    "#----------------------------------classification report ----------------------------------------------------------------------\n",
    "print('classification report')\n",
    "print(classification_report(y_test_under_samp, y2_pred))\n",
    "print('\\n\\n')\n",
    "#-----------------------------------classification accuracy -------------------------------------------------------------------\n",
    "TP = cm[0,0]\n",
    "TN = cm[1,1]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "\n",
    "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))\n",
    "print('\\n\\n')\n",
    "\n",
    "#----------------------------------------classification error------------------------------------------------------------------\n",
    "\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification error : {0:0.4f}'.format(classification_error))\n",
    "print('\\n\\n')\n",
    "\n",
    "#----------------------------------------precision-----------------------------------------------------------------------------\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print('Precision : {0:0.4f}'.format(precision))\n",
    "print('\\n\\n')\n",
    "\n",
    "#--------------------------------------------Recall---------------------------------------------------------------------------\n",
    "recall = TP / float(TP + FN)\n",
    "\n",
    "print('Recall or Sensitivity : {0:0.4f}'.format(recall))\n",
    "print('\\n\\n')\n",
    "#--------------------------------------Truepositive rate------------------------------------------------------------------------\n",
    "\n",
    "true_positive_rate = TP / float(TP + FN)\n",
    "\n",
    "print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))\n",
    "print('\\n\\n')\n",
    "\n",
    "#--------------------------------------false positive rate---------------------------------------------------------------------\n",
    "false_positive_rate = FP / float(FP + TN)\n",
    "\n",
    "print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))\n",
    "print('\\n\\n')\n",
    "#------------------------------------------ Specificity (True Negative Rate) --------------------------------------------------\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print('Specificity : {0:0.4f}'.format(specificity))\n",
    "print('\\n\\n')\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enesamble Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "votingC = VotingClassifier(estimators=[('xgb', xgb_best), ('lgb',lgb_best), ('gbc',gbc_best)], voting='soft')\n",
    "\n",
    "votingC = votingC.fit(X_train_under_samp, y_train_under_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#predict train set \n",
    "print('train set')\n",
    "y1_pred = votingC.predict(X_train_under_samp)\n",
    "# print the accuracy\n",
    "print('voting ensamble Classifier model accuracy score for train set : {0:0.4f}'. format(accuracy_score(y_train_under_samp, y1_pred)))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#predict test set\n",
    "print('test set')\n",
    "y2_pred = votingC.predict(X_test_under_samp)\n",
    "# print the accuracy\n",
    "print('voting ensamble Classifier model accuracy score for test set : {0:0.4f}\\n\\n'. format(accuracy_score(y_test_under_samp, y2_pred)))\n",
    "\n",
    "#-------------------------------------------------confusion matrix-----------------------------------------------------------\n",
    "\n",
    "# print confusion-matrix\n",
    "\n",
    "cm = confusion_matrix(y_test_under_samp, y2_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP){type 1 error} = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN){type 2 error} = ', cm[1,0])\n",
    "print('\\n\\n')\n",
    "\n",
    "#-------------------------------visualization of confusion matrix -----------------------------------------------------------\n",
    "\n",
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "\n",
    "#----------------------------------classification report ----------------------------------------------------------------------\n",
    "print('classification report')\n",
    "print(classification_report(y_test_under_samp, y2_pred))\n",
    "print('\\n\\n')\n",
    "#-----------------------------------classification accuracy -------------------------------------------------------------------\n",
    "TP = cm[0,0]\n",
    "TN = cm[1,1]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "\n",
    "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))\n",
    "print('\\n\\n')\n",
    "\n",
    "#----------------------------------------classification error------------------------------------------------------------------\n",
    "\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification error : {0:0.4f}'.format(classification_error))\n",
    "print('\\n\\n')\n",
    "\n",
    "#----------------------------------------precision-----------------------------------------------------------------------------\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print('Precision : {0:0.4f}'.format(precision))\n",
    "print('\\n\\n')\n",
    "\n",
    "#--------------------------------------------Recall---------------------------------------------------------------------------\n",
    "recall = TP / float(TP + FN)\n",
    "\n",
    "print('Recall or Sensitivity : {0:0.4f}'.format(recall))\n",
    "print('\\n\\n')\n",
    "#--------------------------------------Truepositive rate------------------------------------------------------------------------\n",
    "\n",
    "true_positive_rate = TP / float(TP + FN)\n",
    "\n",
    "print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))\n",
    "print('\\n\\n')\n",
    "\n",
    "#--------------------------------------false positive rate---------------------------------------------------------------------\n",
    "false_positive_rate = FP / float(FP + TN)\n",
    "\n",
    "print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))\n",
    "print('\\n\\n')\n",
    "#------------------------------------------ Specificity (True Negative Rate) --------------------------------------------------\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print('Specificity : {0:0.4f}'.format(specificity))\n",
    "print('\\n\\n')\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if we see that XGBClassifier is giving better result than this voting classifier so i will design our model with XGBClassifier only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
